{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7caeece3-8483-4eb3-a1bc-c04a9a5d799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrix\n",
    "\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.censor_weights = None\n",
    "        self.switch_weights = None if estimand != \"Per-Protocol\" else {}\n",
    "        self.expanded_data = None\n",
    "        self.outcome_model = None\n",
    "        self.outcome_data = None\n",
    "        self.save_dir = None\n",
    "\n",
    "    def set_data(self, data, id=\"id\", period=\"period\", treatment=\"treatment\", outcome=\"outcome\", eligible=\"eligible\", censor_event=\"censored\"):\n",
    "        data = data.rename(columns={id: \"id\", period: \"period\", treatment: \"treatment\", outcome: \"outcome\", eligible: \"eligible\", censor_event: \"censored\"})\n",
    "        data = data.sort_values(by=[\"id\", \"period\"])\n",
    "        data[\"treatment_lag\"] = data.groupby(\"id\")[\"treatment\"].shift(1).fillna(0)\n",
    "        if self.estimand == \"Per-Protocol\":\n",
    "            data[\"switch\"] = (data[\"treatment\"] != data[\"treatment_lag\"]) & (~data[\"treatment_lag\"].isna())\n",
    "        self.data = data\n",
    "        return self\n",
    "\n",
    "    def set_censor_weight_model(self, censor_event, numerator, denominator, pool_models, model_fitter, save_path=None):\n",
    "        self.censor_weights = {\n",
    "            \"censor_event\": censor_event,\n",
    "            \"numerator\": numerator,\n",
    "            \"denominator\": denominator,\n",
    "            \"pool_models\": pool_models,\n",
    "            \"model_fitter\": model_fitter,\n",
    "            \"save_path\": save_path,\n",
    "            \"fitted_models\": {}\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def set_switch_weight_model(self, numerator, denominator, model_fitter, save_path=None):\n",
    "        if self.estimand != \"Per-Protocol\":\n",
    "            raise ValueError(\"Switch weights are only applicable for Per-Protocol estimand.\")\n",
    "        self.switch_weights = {\n",
    "            \"numerator\": numerator,\n",
    "            \"denominator\": denominator,\n",
    "            \"model_fitter\": model_fitter,\n",
    "            \"save_path\": save_path,\n",
    "            \"fitted_models\": {}\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def print_model_summary(self, model, title):\n",
    "        print(f\"{title}:\")\n",
    "        print(\"term        estimate   std.error statistic p.value\")\n",
    "        for param in model.params.index:\n",
    "            term = \"(Intercept)\" if param == \"Intercept\" else param\n",
    "            estimate = model.params[param]\n",
    "            std_error = model.bse[param]\n",
    "            statistic = model.tvalues[param]\n",
    "            p_value = model.pvalues[param]\n",
    "            print(f\"{term:<12}{estimate:>10.6f}{std_error:>12.6f}{statistic:>10.4f}{p_value:>12.4e}\")\n",
    "        null_deviance = -2 * model.llnull\n",
    "        deviance = -2 * model.llf\n",
    "        df_null = int(model.nobs - 1)\n",
    "        print(\"\\nnull.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\")\n",
    "        print(f\"{null_deviance:>13.4f}{df_null:>8d}{model.llf:>10.4f}{model.aic:>10.4f}{model.bic:>10.4f}{deviance:>10.4f}{int(model.df_resid):>12d}{int(model.nobs):>5d}\")\n",
    "        print()\n",
    "\n",
    "    def calculate_weights(self):\n",
    "        if self.censor_weights is None:\n",
    "            raise ValueError(\"Censor weight model not specified.\")\n",
    "        \n",
    "        data = self.data.copy()\n",
    "        censor_event = self.censor_weights[\"censor_event\"]\n",
    "        data[\"not_censored\"] = 1 - data[censor_event]\n",
    "        \n",
    "        print(f\"Step 4: Weight Models for Informative Censoring ({self.estimand})\")\n",
    "        print(\"---------------------------------------\")\n",
    "        \n",
    "        if self.censor_weights[\"pool_models\"] == \"numerator\":\n",
    "            num_formula = f\"not_censored ~ {self.censor_weights['numerator']}\"\n",
    "            model_n = smf.logit(num_formula, data=data).fit(disp=0)\n",
    "            self.censor_weights[\"fitted_models\"][\"n\"] = model_n\n",
    "            \n",
    "            den_formula = f\"not_censored ~ {self.censor_weights['denominator']}\"\n",
    "            model_d0 = smf.logit(den_formula, data=data[data[\"treatment_lag\"] == 0]).fit(disp=0)\n",
    "            model_d1 = smf.logit(den_formula, data=data[data[\"treatment_lag\"] == 1]).fit(disp=0)\n",
    "            self.censor_weights[\"fitted_models\"][\"d0\"] = model_d0\n",
    "            self.censor_weights[\"fitted_models\"][\"d1\"] = model_d1\n",
    "            \n",
    "            data[\"censor_prob_num\"] = model_n.predict(data)\n",
    "            data[\"censor_prob_den\"] = np.where(\n",
    "                data[\"treatment_lag\"] == 0,\n",
    "                model_d0.predict(data),\n",
    "                model_d1.predict(data)\n",
    "            )\n",
    "            self.print_model_summary(model_n, \"Numerator Model (Pooled)\")\n",
    "            self.print_model_summary(model_d0, \"Denominator Model (Treatment Lag = 0)\")\n",
    "            self.print_model_summary(model_d1, \"Denominator Model (Treatment Lag = 1)\")\n",
    "        else:\n",
    "            num_formula = f\"not_censored ~ {self.censor_weights['numerator']}\"\n",
    "            model_n0 = smf.logit(num_formula, data=data[data[\"treatment_lag\"] == 0]).fit(disp=0)\n",
    "            model_n1 = smf.logit(num_formula, data=data[data[\"treatment_lag\"] == 1]).fit(disp=0)\n",
    "            den_formula = f\"not_censored ~ {self.censor_weights['denominator']}\"\n",
    "            model_d0 = smf.logit(den_formula, data=data[data[\"treatment_lag\"] == 0]).fit(disp=0)\n",
    "            model_d1 = smf.logit(den_formula, data=data[data[\"treatment_lag\"] == 1]).fit(disp=0)\n",
    "            self.censor_weights[\"fitted_models\"][\"n0\"] = model_n0\n",
    "            self.censor_weights[\"fitted_models\"][\"n1\"] = model_n1\n",
    "            self.censor_weights[\"fitted_models\"][\"d0\"] = model_d0\n",
    "            self.censor_weights[\"fitted_models\"][\"d1\"] = model_d1\n",
    "            \n",
    "            data[\"censor_prob_num\"] = np.where(\n",
    "                data[\"treatment_lag\"] == 0,\n",
    "                model_n0.predict(data),\n",
    "                model_n1.predict(data)\n",
    "            )\n",
    "            data[\"censor_prob_den\"] = np.where(\n",
    "                data[\"treatment_lag\"] == 0,\n",
    "                model_d0.predict(data),\n",
    "                model_d1.predict(data)\n",
    "            )\n",
    "            self.print_model_summary(model_n0, \"Numerator Model (Treatment Lag = 0)\")\n",
    "            self.print_model_summary(model_n1, \"Numerator Model (Treatment Lag = 1)\")\n",
    "            self.print_model_summary(model_d0, \"Denominator Model (Treatment Lag = 0)\")\n",
    "            self.print_model_summary(model_d1, \"Denominator Model (Treatment Lag = 1)\")\n",
    "        \n",
    "        data[\"wtC\"] = data[\"censor_prob_num\"] / data[\"censor_prob_den\"]\n",
    "        data[\"wtC\"] = data.groupby(\"id\")[\"wtC\"].cumprod()\n",
    "        \n",
    "        if self.estimand == \"Per-Protocol\" and self.switch_weights:\n",
    "            data[\"stayed_on_treatment\"] = (~data[\"switch\"]).astype(int)\n",
    "            num_formula = f\"stayed_on_treatment ~ {self.switch_weights['numerator']}\"\n",
    "            den_formula = f\"stayed_on_treatment ~ {self.switch_weights['denominator']}\"\n",
    "            \n",
    "            model_n0 = smf.logit(num_formula, data=data[data[\"treatment_lag\"] == 0]).fit(disp=0)\n",
    "            model_n1 = smf.logit(num_formula, data=data[data[\"treatment_lag\"] == 1]).fit(disp=0)\n",
    "            model_d0 = smf.logit(den_formula, data=data[data[\"treatment_lag\"] == 0]).fit(disp=0)\n",
    "            model_d1 = smf.logit(den_formula, data=data[data[\"treatment_lag\"] == 1]).fit(disp=0)\n",
    "            self.switch_weights[\"fitted_models\"][\"n0\"] = model_n0\n",
    "            self.switch_weights[\"fitted_models\"][\"n1\"] = model_n1\n",
    "            self.switch_weights[\"fitted_models\"][\"d0\"] = model_d0\n",
    "            self.switch_weights[\"fitted_models\"][\"d1\"] = model_d1\n",
    "            \n",
    "            data[\"switch_prob_num\"] = np.where(\n",
    "                data[\"treatment_lag\"] == 0,\n",
    "                model_n0.predict(data),\n",
    "                model_n1.predict(data)\n",
    "            )\n",
    "            data[\"switch_prob_den\"] = np.where(\n",
    "                data[\"treatment_lag\"] == 0,\n",
    "                model_d0.predict(data),\n",
    "                model_d1.predict(data)\n",
    "            )\n",
    "            data[\"wtS\"] = data[\"switch_prob_num\"] / data[\"switch_prob_den\"]\n",
    "            data[\"wtS\"] = data.groupby(\"id\")[\"wtS\"].cumprod()\n",
    "            data[\"weight\"] = data[\"wtC\"] * data[\"wtS\"]\n",
    "            \n",
    "            print(\"Switch Weight Models:\")\n",
    "            self.print_model_summary(model_n0, \"Numerator Model (Treatment Lag = 0)\")\n",
    "            self.print_model_summary(model_n1, \"Numerator Model (Treatment Lag = 1)\")\n",
    "            self.print_model_summary(model_d0, \"Denominator Model (Treatment Lag = 0)\")\n",
    "            self.print_model_summary(model_d1, \"Denominator Model (Treatment Lag = 1)\")\n",
    "        else:\n",
    "            data[\"weight\"] = data[\"wtC\"]\n",
    "        \n",
    "        self.data = data\n",
    "        return self\n",
    "\n",
    "    def set_outcome_model(self, adjustment_terms=\"x2\"):\n",
    "        print(\"Step 5: Outcome Model Specification\")\n",
    "        print(\"-----------------------------------\")\n",
    "        terms = \"assigned_treatment + x2 + followup_time + I(followup_time**2) + trial_period + I(trial_period**2)\"\n",
    "        if adjustment_terms:\n",
    "            terms += f\" + {adjustment_terms}\"\n",
    "        self.outcome_model = {\"formula\": f\"outcome ~ {terms}\", \"fitted\": None}\n",
    "        print(f\"Outcome Model Formula: {self.outcome_model['formula']}\\n\")\n",
    "        return self\n",
    "\n",
    "    def set_expansion_options(self, output=\"memory\", chunk_size=500):\n",
    "        self.expansion_options = {\"output\": output, \"chunk_size\": chunk_size}\n",
    "        return self\n",
    "\n",
    "    def expand_trials(self):\n",
    "        data = self.data.copy()\n",
    "        periods = data[\"period\"].unique()\n",
    "        expanded_rows = []\n",
    "        \n",
    "        for trial_period in periods:\n",
    "            eligible = data[(data[\"period\"] == trial_period) & (data[\"eligible\"] == 1)]\n",
    "            for _, row in eligible.iterrows():\n",
    "                patient_data = data[data[\"id\"] == row[\"id\"]]\n",
    "                start_idx = patient_data.index[patient_data[\"period\"] == trial_period][0]\n",
    "                follow_up = patient_data.loc[start_idx:]\n",
    "                \n",
    "                assigned_treatment = row[\"treatment\"]\n",
    "                for t, f_row in enumerate(follow_up.itertuples()):\n",
    "                    expanded_row = {\n",
    "                        \"id\": row[\"id\"],\n",
    "                        \"trial_period\": trial_period,\n",
    "                        \"followup_time\": t,\n",
    "                        \"outcome\": f_row.outcome,\n",
    "                        \"weight\": f_row.weight,\n",
    "                        \"treatment\": f_row.treatment,\n",
    "                        \"assigned_treatment\": assigned_treatment,\n",
    "                        \"x2\": f_row.x2,\n",
    "                        \"age\": f_row.age\n",
    "                    }\n",
    "                    if self.estimand == \"Per-Protocol\" and f_row.switch:\n",
    "                        break\n",
    "                    expanded_rows.append(expanded_row)\n",
    "        \n",
    "        self.expanded_data = pd.DataFrame(expanded_rows)\n",
    "        print(\"Step 6: Trial Expansion\")\n",
    "        print(\"------------------------\")\n",
    "        print(f\"Expanded Data: {self.expanded_data.shape[0]} rows, {self.expanded_data.shape[1]} columns\")\n",
    "        print(\"First few rows of expanded data:\")\n",
    "        print(self.expanded_data.head().to_string(index=True), \"\\n\")\n",
    "        return self\n",
    "\n",
    "    def load_expanded_data(self, seed=1234, p_control=0.5):\n",
    "        np.random.seed(seed)\n",
    "        expanded = self.expanded_data.copy()\n",
    "        control_mask = (expanded[\"outcome\"] == 0)\n",
    "        sample_mask = control_mask & (np.random.random(len(expanded)) < p_control)\n",
    "        self.outcome_data = expanded[sample_mask | ~control_mask].copy()\n",
    "        self.outcome_data[\"sample_weight\"] = np.where(self.outcome_data[\"outcome\"] == 0, 1 / p_control, 1)\n",
    "        print(\"Step 7: Load Expanded Data\")\n",
    "        print(\"--------------------------\")\n",
    "        print(f\"Loaded Data: {self.outcome_data.shape[0]} rows\")\n",
    "        print(\"First few rows of loaded data:\")\n",
    "        print(self.outcome_data.head().to_string(index=True), \"\\n\")\n",
    "        return self\n",
    "\n",
    "    def fit_msm(self, weight_cols=[\"weight\", \"sample_weight\"], modify_weights=None):\n",
    "        data = self.outcome_data.copy()\n",
    "        data[\"w\"] = data[weight_cols].prod(axis=1)\n",
    "        if modify_weights:\n",
    "            data[\"w\"] = modify_weights(data[\"w\"])\n",
    "        \n",
    "        model = smf.logit(self.outcome_model[\"formula\"], data=data, weights=data[\"w\"]).fit(disp=0)\n",
    "        self.outcome_model[\"fitted\"] = model\n",
    "        print(\"Step 8: Fit Marginal Structural Model\")\n",
    "        print(\"-------------------------------------\")\n",
    "        print(\"Marginal Structural Model Summary:\")\n",
    "        print(model.summary())\n",
    "        print()\n",
    "        return self\n",
    "\n",
    "    def predict(self, newdata, predict_times):\n",
    "        model = self.outcome_model[\"fitted\"]\n",
    "        params = model.params\n",
    "        cov = model.cov_params()\n",
    "        n_bootstrap = 1000\n",
    "        bootstrap_params = np.random.multivariate_normal(params, cov, size=n_bootstrap)\n",
    "\n",
    "        rhs = self.outcome_model[\"formula\"].split(\"~\")[1].strip()\n",
    "        mean_row = newdata[newdata[\"trial_period\"] == 1].mean().to_frame().T\n",
    "        ref_data = pd.concat([mean_row] * len(predict_times) * 2, ignore_index=True)\n",
    "        ref_data[\"followup_time\"] = predict_times * 2\n",
    "        ref_data[\"assigned_treatment\"] = [0] * len(predict_times) + [1] * len(predict_times)\n",
    "\n",
    "        X_pred = dmatrix(rhs, ref_data, return_type=\"dataframe\")\n",
    "        trt0_mask = ref_data[\"assigned_treatment\"] == 0\n",
    "        X_pred_trt0 = X_pred[trt0_mask]\n",
    "        X_pred_trt1 = X_pred[~trt0_mask]\n",
    "\n",
    "        linear_pred_trt0 = np.dot(X_pred_trt0, params)\n",
    "        p_trt0 = 1 / (1 + np.exp(-linear_pred_trt0))\n",
    "        survival_trt0 = np.cumprod(1 - p_trt0)\n",
    "\n",
    "        linear_pred_trt1 = np.dot(X_pred_trt1, params)\n",
    "        p_trt1 = 1 / (1 + np.exp(-linear_pred_trt1))\n",
    "        survival_trt1 = np.cumprod(1 - p_trt1)\n",
    "\n",
    "        diff = survival_trt1 - survival_trt0\n",
    "\n",
    "        diff_bootstrap = np.zeros((n_bootstrap, len(predict_times)))\n",
    "        for i in range(n_bootstrap):\n",
    "            beta_i = bootstrap_params[i]\n",
    "            linear_pred_trt0_i = np.dot(X_pred_trt0, beta_i)\n",
    "            p_trt0_i = 1 / (1 + np.exp(-linear_pred_trt0_i))\n",
    "            survival_trt0_i = np.cumprod(1 - p_trt0_i)\n",
    "\n",
    "            linear_pred_trt1_i = np.dot(X_pred_trt1, beta_i)\n",
    "            p_trt1_i = 1 / (1 + np.exp(-linear_pred_trt1_i))\n",
    "            survival_trt1_i = np.cumprod(1 - p_trt1_i)\n",
    "\n",
    "            diff_bootstrap[i, :] = survival_trt1_i - survival_trt0_i\n",
    "\n",
    "        ci_lower = np.percentile(diff_bootstrap, 2.5, axis=0)\n",
    "        ci_upper = np.percentile(diff_bootstrap, 97.5, axis=0)\n",
    "\n",
    "        return {\n",
    "            \"difference\": {\n",
    "                \"followup_time\": predict_times,\n",
    "                \"survival_diff\": diff,\n",
    "                \"ci_lower\": ci_lower,\n",
    "                \"ci_upper\": ci_upper\n",
    "            }\n",
    "        }\n",
    "\n",
    "class TrialSequenceITT(TrialSequence):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Intention-to-Treat\")\n",
    "\n",
    "    def set_censor_weight_model(self, censor_event=\"censored\", numerator=\"x2\", denominator=\"x2 + x1\", pool_models=\"numerator\", model_fitter=\"stats_glm_logit\", save_path=None):\n",
    "        return super().set_censor_weight_model(censor_event, numerator, denominator, pool_models, model_fitter, save_path)\n",
    "\n",
    "class TrialSequencePP(TrialSequence):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Per-Protocol\")\n",
    "\n",
    "    def set_censor_weight_model(self, censor_event=\"censored\", numerator=\"x2\", denominator=\"x2 + x1\", pool_models=\"none\", model_fitter=\"stats_glm_logit\", save_path=None):\n",
    "        return super().set_censor_weight_model(censor_event, numerator, denominator, pool_models, model_fitter, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc50cef7-d09d-4eab-8c61-fa948021dfe3",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00d38374-1092-4ef2-ab54-99bb67b14b87",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Step 1: Setup\n",
    "trial_itt = TrialSequenceITT()\n",
    "trial_pp = TrialSequencePP()\n",
    "\n",
    "trial_itt_dir = os.path.join(os.path.abspath(\".\"), \"trial_itt\")\n",
    "trial_pp_dir = os.path.join(os.path.abspath(\".\"), \"trial_pp\")\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "trial_itt.save_dir = trial_itt_dir\n",
    "trial_pp.save_dir = trial_pp_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f27178-2ccb-445b-859d-b53f1e2445fb",
   "metadata": {},
   "source": [
    "# 2. Data preparation\n",
    "Next the user must specify the observational input data that will be used for the target trial emulation. Here we need to specify which columns contain which values and how they should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcf14606-c8d6-4603-b435-9c907166d2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
      "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
      "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
      "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
      "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
      "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
      "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
      "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
      "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
      "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
      "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
      "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
      "\n",
      "     outcome  censored  eligible  \n",
      "0          0         0         1  \n",
      "1          0         0         0  \n",
      "2          0         0         0  \n",
      "3          0         0         0  \n",
      "4          0         0         0  \n",
      "..       ...       ...       ...  \n",
      "720        0         0         0  \n",
      "721        0         0         0  \n",
      "722        0         0         0  \n",
      "723        0         0         0  \n",
      "724        1         0         0  \n",
      "\n",
      "[725 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Data Preparation\n",
    "file_path = \"data/data_censored.csv\"  # Replace with your actual file path\n",
    "data_censored = pd.read_csv(file_path)\n",
    "trial_itt.set_data(data_censored)\n",
    "trial_pp.set_data(data_censored)\n",
    "print(data_censored)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d551a3-d0c3-46fd-a83e-3e04b89ddcb9",
   "metadata": {},
   "source": [
    "# 3. Weight models and censoring\n",
    "To adjust for the effects of informative censoring, inverse probability of censoring weights (IPCW) can be applied. To estimate these weights, we construct time-to-(censoring) event models. Two sets of models are fit for the two censoring mechanisms which may apply: censoring due to deviation from assigned treatment and other informative censoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d803b7-2f1f-4901-a4ab-596f0022a648",
   "metadata": {},
   "source": [
    "# 3.1 Censoring due to treatment switching\n",
    "We specify model formulas to be used for calculating the probability of receiving treatment in the current period. Separate models are fitted for patients who had treatment = 1 and those who had treatment = 0 in the previous period. Stabilized weights are used by fitting numerator and denominator models.\n",
    "\n",
    "There are optional arguments to specify columns which can include/exclude observations from the treatment models. These are used in case it is not possible for a patient to deviate from a certain treatment assignment in that period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04afe560-b912-4f7a-98f5-ea0be81ea384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TrialSequencePP at 0x270950d24b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Step 3: Weight Models for Censoring\n",
    "trial_pp.set_switch_weight_model(numerator=\"age\", denominator=\"age + x1 + x3\", model_fitter=\"stats_glm_logit\", save_path=trial_pp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1531756-7ebb-43dd-af8a-c35a80f4d9fc",
   "metadata": {},
   "source": [
    "# 3.2 Other informative censoring\n",
    "In case there is other informative censoring occurring in the data, we can create similar models to estimate the IPCW. These can be used with all types of estimand. We need to specifycensor_event which is the column containing the censoring indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8376bec-0353-44ec-8ef4-6ceed4781b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TrialSequencePP at 0x270950d24b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_itt.set_censor_weight_model(save_path=trial_itt_dir)\n",
    "trial_pp.set_censor_weight_model(save_path=trial_pp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cfee25-8f99-4fc0-b232-80efc9ea29fe",
   "metadata": {},
   "source": [
    "# 4. Calculate Weights\n",
    "Next we need to fit the individual models and combine them into weights. This is done with calculate_weights()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34ce2244-1f8a-45d6-9f27-e78cc307a891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Weight Models for Informative Censoring (Intention-to-Treat)\n",
      "---------------------------------------\n",
      "Numerator Model (Pooled):\n",
      "term        estimate   std.error statistic p.value\n",
      "(Intercept)   2.448091    0.140575   17.4149  6.3626e-68\n",
      "x2           -0.448648    0.136878   -3.2777  1.0465e-03\n",
      "\n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "     404.2156     724 -196.7002  397.4004  406.5727  393.4004         723  725\n",
      "\n",
      "Denominator Model (Treatment Lag = 0):\n",
      "term        estimate   std.error statistic p.value\n",
      "(Intercept)   1.894196    0.207114    9.1457  5.9253e-20\n",
      "x2           -0.589829    0.169342   -3.4831  4.9572e-04\n",
      "x1            0.855260    0.345299    2.4769  1.3254e-02\n",
      "\n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "     283.0723     425 -132.1655  270.3309  282.4943  264.3309         423  426\n",
      "\n",
      "Denominator Model (Treatment Lag = 1):\n",
      "term        estimate   std.error statistic p.value\n",
      "(Intercept)   2.814434    0.312269    9.0129  2.0076e-19\n",
      "x2           -0.037132    0.269959   -0.1375  8.9060e-01\n",
      "x1            0.893514    0.777206    1.1496  2.5029e-01\n",
      "\n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "     113.0528     298  -55.7294  117.4588  128.5601  111.4588         296  299\n",
      "\n",
      "Step 4: Weight Models for Informative Censoring (Per-Protocol)\n",
      "---------------------------------------\n",
      "Numerator Model (Treatment Lag = 0):\n",
      "term        estimate   std.error statistic p.value\n",
      "(Intercept)   2.245008    0.171771   13.0698  4.8986e-39\n",
      "x2           -0.573941    0.167010   -3.4366  5.8912e-04\n",
      "\n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "     283.0723     425 -135.4361  274.8722  282.9811  270.8722         424  426\n",
      "\n",
      "Numerator Model (Treatment Lag = 1):\n",
      "term        estimate   std.error statistic p.value\n",
      "(Intercept)   3.011579    0.287339   10.4809  1.0570e-25\n",
      "x2           -0.005692    0.270506   -0.0210  9.8321e-01\n",
      "\n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "     113.0528     298  -56.5262  117.0524  124.4533  113.0524         297  299\n",
      "\n",
      "Denominator Model (Treatment Lag = 0):\n",
      "term        estimate   std.error statistic p.value\n",
      "(Intercept)   1.894196    0.207114    9.1457  5.9253e-20\n",
      "x2           -0.589829    0.169342   -3.4831  4.9572e-04\n",
      "x1            0.855260    0.345299    2.4769  1.3254e-02\n",
      "\n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "     283.0723     425 -132.1655  270.3309  282.4943  264.3309         423  426\n",
      "\n",
      "Denominator Model (Treatment Lag = 1):\n",
      "term        estimate   std.error statistic p.value\n",
      "(Intercept)   2.814434    0.312269    9.0129  2.0076e-19\n",
      "x2           -0.037132    0.269959   -0.1375  8.9060e-01\n",
      "x1            0.893514    0.777206    1.1496  2.5029e-01\n",
      "\n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "     113.0528     298  -55.7294  117.4588  128.5601  111.4588         296  299\n",
      "\n",
      "Switch Weight Models:\n",
      "Numerator Model (Treatment Lag = 0):\n",
      "term        estimate   std.error statistic p.value\n",
      "(Intercept)  -1.594883    0.438099   -3.6405  2.7215e-04\n",
      "age           0.046289    0.008992    5.1477  2.6364e-07\n",
      "\n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "     550.2502     425 -260.8109  525.6219  533.7307  521.6219         424  426\n",
      "\n",
      "Numerator Model (Treatment Lag = 1):\n",
      "term        estimate   std.error statistic p.value\n",
      "(Intercept)   2.039610    0.542092    3.7625  1.6824e-04\n",
      "age          -0.031052    0.011046   -2.8112  4.9359e-03\n",
      "\n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "     391.1565     298 -191.4956  386.9911  394.3920  382.9911         297  299\n",
      "\n",
      "Denominator Model (Treatment Lag = 0):\n",
      "term        estimate   std.error statistic p.value\n",
      "(Intercept)  -1.490694    0.470815   -3.1662  1.5445e-03\n",
      "age           0.049125    0.009213    5.3321  9.7110e-08\n",
      "x1           -0.595126    0.214955   -2.7686  5.6296e-03\n",
      "x3            0.139297    0.214121    0.6506  5.1533e-01\n",
      "\n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "     550.2502     425 -256.6657  521.3314  537.5492  513.3314         422  426\n",
      "\n",
      "Denominator Model (Treatment Lag = 1):\n",
      "term        estimate   std.error statistic p.value\n",
      "(Intercept)   1.754733    0.586036    2.9942  2.7513e-03\n",
      "age          -0.030293    0.011279   -2.6857  7.2383e-03\n",
      "x1            0.654404    0.289161    2.2631  2.3629e-02\n",
      "x3            0.161507    0.250179    0.6456  5.1856e-01\n",
      "\n",
      "null.deviance df.null logLik    AIC      BIC      deviance df.residual nobs\n",
      "     391.1565     298 -188.6727  385.3454  400.1472  377.3454         295  299\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TrialSequencePP at 0x270950d24b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Step 4: Calculate Weights\n",
    "trial_itt.calculate_weights()\n",
    "trial_pp.calculate_weights()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f60e9a-bca9-43e4-811d-c51989c9da5f",
   "metadata": {},
   "source": [
    "# 5. Specify Outcome Model\n",
    "Now we can specify the outcome model. Here we can include adjustment terms for any variables in the dataset. The numerator terms from the stabilised weight models are automatically included in the outcome model formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b91f3d-b78e-432a-a25a-4dc297506b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Step 5: Specify Outcome Model (ITT only for this example)\n",
    "trial_itt.set_outcome_model(adjustment_terms=\"x2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874c5199-97ae-4d6c-aaef-8ab3cd360cba",
   "metadata": {},
   "source": [
    "# 6. Expand Trials\n",
    "Now we are ready to create the data set with all of the sequence of target trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df122f43-2089-4bbe-b35f-2e5984a251b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Step 6: Expand Trials\n",
    "trial_itt.set_expansion_options().expand_trials()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058854b8-8750-4009-8b12-09a3f3f16de7",
   "metadata": {},
   "source": [
    "# 7. Load or Sample from Expanded Data\n",
    "Now that the expanded data has been created, we can prepare the data to fit the outcome model. For data that can fit comfortably in memory, this is a trivial step using load_expanded_data.\n",
    "\n",
    "For large datasets, it may be necessary to sample from the expanded by setting the p_control argument. This sets the probability that an observation with outcome == 0 will be included in the loaded data. A seed can be set for reproducibility. Additionally, a vector of periods to include can be specified, e.g., period = 1:60, and/or a subsetting condition, subset_condition = \"age > 65\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0bae3f0-c8d5-4a7b-b2a7-c39638ea2a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7: Load Expanded Data\n",
      "--------------------------\n",
      "Loaded Data: 781 rows\n",
      "First few rows of loaded data:\n",
      "     id  trial_period  followup_time  outcome    weight  treatment  assigned_treatment        x2  age  sample_weight\n",
      "0   1.0             0              0        0  0.983546          1                 1.0  1.146148   36            2.0\n",
      "2   1.0             0              2        0  0.918067          1                 1.0 -0.481762   38            2.0\n",
      "5   1.0             0              5        0  0.818868          1                 1.0 -0.057482   41            2.0\n",
      "6   2.0             0              0        0  0.980690          0                 0.0 -0.802142   26            2.0\n",
      "10  2.0             0              4        0  0.933132          1                 0.0  1.173178   30            2.0 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TrialSequenceITT at 0x270950d0290>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  # Step 7: Load Expanded Data\n",
    "trial_itt.load_expanded_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8fe706-4a45-4f0a-8b55-eddca735c588",
   "metadata": {},
   "source": [
    "# 8. Fit Marginal Structural Model\n",
    "To fit the outcome model we use fit_msm()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26d3283b-15a0-4337-94b2-8261302313dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8: Fit Marginal Structural Model\n",
      "-------------------------------------\n",
      "Marginal Structural Model Summary:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                outcome   No. Observations:                  781\n",
      "Model:                          Logit   Df Residuals:                      774\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                  0.1654\n",
      "Time:                        00:53:44   Log-Likelihood:                -58.565\n",
      "converged:                      False   LL-Null:                       -70.175\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0007262\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -5.2392      0.913     -5.738      0.000      -7.029      -3.450\n",
      "assigned_treatment        1.5185      0.660      2.301      0.021       0.225       2.812\n",
      "x2                        0.2049      0.279      0.734      0.463      -0.342       0.752\n",
      "followup_time             0.3526      0.209      1.689      0.091      -0.056       0.762\n",
      "I(followup_time ** 2)    -0.0218      0.013     -1.710      0.087      -0.047       0.003\n",
      "trial_period              7.5713   1440.710      0.005      0.996   -2816.169    2831.311\n",
      "I(trial_period ** 2)     -7.9966   1440.710     -0.006      0.996   -2831.736    2815.743\n",
      "=========================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.34 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thris\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\base\\model.py:130: ValueWarning: unknown kwargs ['weights']\n",
      "  warnings.warn(msg, ValueWarning)\n",
      "C:\\Users\\thris\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\discrete\\discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "C:\\Users\\thris\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\thris\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\base\\model.py:130: ValueWarning: unknown kwargs ['weights']\n",
      "  warnings.warn(msg, ValueWarning)\n",
      "C:\\Users\\thris\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\discrete\\discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TrialSequenceITT at 0x270950d0290>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    # Step 8: Fit Marginal Structural Model\n",
    "trial_itt.fit_msm(modify_weights=lambda w: np.minimum(w, np.quantile(w, 0.99)))\n",
    "\n",
    "    # Step 9: Inference\n",
    "predict_times = list(range(11))\n",
    "newdata = trial_itt.outcome_data[trial_itt.outcome_data[\"trial_period\"] == 1]\n",
    "preds = trial_itt.predict(newdata, predict_times)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(preds[\"difference\"][\"followup_time\"], preds[\"difference\"][\"survival_diff\"], 'b-', label=\"Survival Difference\")\n",
    "plt.plot(preds[\"difference\"][\"followup_time\"], preds[\"difference\"][\"ci_lower\"], 'r--', label=\"2.5% CI\")\n",
    "plt.plot(preds[\"difference\"][\"followup_time\"], preds[\"difference\"][\"ci_upper\"], 'r--', label=\"97.5% CI\")\n",
    "plt.xlabel(\"Follow up\")\n",
    "plt.ylabel(\"Survival difference\")\n",
    "plt.ylim(-0.8, 0.1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5be9e-7eae-4160-8c1c-93e93335d13b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
