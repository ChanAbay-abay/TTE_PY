{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>Target Trial Emulation</h1>\n",
    "    By Christian Abay-abay & Thristan Jay Nakila\n",
    "</center>\n",
    "\n",
    "## **Instructions**\n",
    "\n",
    "1. Extract the dummy data from [RPubs - TTE](https://rpubs.com/alanyang0924/TTE) and save it as `data_censored.csv`.\n",
    "2. Convert the R code to Python in a Jupyter Notebook, ensuring the results match the original.\n",
    "3. Create a second version (`TTE-v2.ipynb`) with additional analysis.\n",
    "4. Integrate clustering in `TTE-v2`, determine where it fits, and generate insights.\n",
    "5. Work in pairs, preferably with your thesis partner.\n",
    "6. Push your Jupyter Notebooks (`TTE.ipynb` and `TTE-v2.ipynb`) to GitHub.\n",
    "7. ðŸ“… **Deadline:** February 28, 2025, at **11:59 PM**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center>\n",
    "    <h2>R Code converted to Python</h2>\n",
    "    R Code from [RPubs - TTE](https://rpubs.com/alanyang0924/TTE) converted to Python code for this notebook.\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (3957436914.py, line 201)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[20], line 201\u001b[1;36m\u001b[0m\n\u001b[1;33m    return self\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "def stats_glm_logit(y, X):\n",
    "    return sm.Logit(y, X).fit(disp=0)\n",
    "# Define the TrialEmulation class\n",
    "class TrialEmulation:\n",
    "    def __init__(self, data=None, id_col=None, period_col=None, treatment_col=None, outcome_col=None, eligible_col=None):\n",
    "        self.data = data\n",
    "        self.id_col = id_col\n",
    "        self.period_col = period_col\n",
    "        self.treatment_col = treatment_col\n",
    "        self.outcome_col = outcome_col\n",
    "        self.eligible_col = eligible_col\n",
    "        self.censor_weights = None\n",
    "        self.switch_weights = {}  # Initialize switch weights as an empty dictionary\n",
    "###################################################\n",
    "    def set_data(self, data, id_col, period_col, treatment_col, outcome_col, eligible_col):\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Data must be a pandas DataFrame.\")\n",
    "        self.data = data.copy()\n",
    "        self.id_col = id_col\n",
    "        self.period_col = period_col\n",
    "        self.treatment_col = treatment_col\n",
    "        self.outcome_col = outcome_col\n",
    "        self.eligible_col = eligible_col\n",
    "        self.data['prev_treatment'] = self.data.groupby(self.id_col)[self.treatment_col].shift(1)\n",
    "        return self\n",
    "    \n",
    "###################################################\n",
    "    def show(self, num_rows=5):\n",
    "        \"\"\"Display dataset head.\"\"\"\n",
    "        if self.data is not None:\n",
    "            print(f\"Dataset Head ({num_rows} rows):\")\n",
    "            print(self.data.head(num_rows))\n",
    "        else:\n",
    "            print(\"No data available in this instance.\")\n",
    "###################################################\n",
    "    def set_switch_weight_model(self, numerator, denominator, model_fitter):\n",
    "        \"\"\"Set the switch weight model formulas and the model fitter.\"\"\"\n",
    "        # Allow model_fitter to be a string identifier or callable; we'll handle it later\n",
    "        if not isinstance(model_fitter, str) and not callable(model_fitter):\n",
    "            raise ValueError(\"model_fitter must be a string identifier or a callable function.\")\n",
    "        \n",
    "        self.switch_weights = {\n",
    "            \"numerator\": numerator,\n",
    "            \"denominator\": denominator,\n",
    "            \"model_fitter\": model_fitter\n",
    "        }\n",
    "        return self  # Allow method chaining\n",
    "###################################################\n",
    "    def calculate_weights(self, save_path=None):\n",
    "        \"\"\"Calculate stabilized weights for treatment switching and censoring.\"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"No data has been set.\")\n",
    "    \n",
    "        # Ensure prev_treatment is available\n",
    "        if 'prev_treatment' not in self.data.columns:\n",
    "            self.data['prev_treatment'] = self.data.groupby(self.id_col)[self.treatment_col].shift(1)\n",
    "    \n",
    "        # 1. Treatment Switching Weights (for PP only)\n",
    "        if self.switch_weights and self.switch_weights.get(\"numerator\"):\n",
    "            try:\n",
    "                num_features = [f.strip() for f in self.switch_weights[\"numerator\"].split(\" + \")]\n",
    "                denom_features = [f.strip() for f in self.switch_weights[\"denominator\"].split(\" + \")]\n",
    "                y = self.data[self.treatment_col]\n",
    "    \n",
    "                # Subset data where prev_treatment is defined (period > 0)\n",
    "                data_switch = self.data.dropna(subset=['prev_treatment'])\n",
    "                y_switch = data_switch[self.treatment_col]\n",
    "    \n",
    "                # Fit models stratified by prev_treatment\n",
    "                switch_weights = {}\n",
    "                numerator_models = {}\n",
    "                denominator_models = {}\n",
    "                for prev_trt in [0, 1]:\n",
    "                    subset = data_switch[data_switch['prev_treatment'] == prev_trt]\n",
    "                    y_current = y_switch.loc[subset.index]\n",
    "                    X_num = sm.add_constant(subset[num_features])\n",
    "                    X_denom = sm.add_constant(subset[denom_features])\n",
    "    \n",
    "                    num_model = self.switch_weights[\"model_fitter\"](y_current, X_num)\n",
    "                    denom_model = self.switch_weights[\"model_fitter\"](y_current, X_denom)\n",
    "                    numerator_models[prev_trt] = num_model\n",
    "                    denominator_models[prev_trt] = denom_model\n",
    "    \n",
    "                    # Predict probabilities\n",
    "                    p_num = num_model.predict(X_num)\n",
    "                    p_denom = denom_model.predict(X_denom)\n",
    "                    switch_weights[prev_trt] = p_num / p_denom  # Stabilized weights\n",
    "    \n",
    "                # Assign weights back to data\n",
    "                self.data['switch_weight'] = 1.0  # Default for period = 0\n",
    "                for prev_trt in [0, 1]:\n",
    "                    mask = self.data['prev_treatment'] == prev_trt\n",
    "                    indices = data_switch[data_switch['prev_treatment'] == prev_trt].index\n",
    "                    self.data.loc[indices, 'switch_weight'] = switch_weights[prev_trt]\n",
    "    \n",
    "                self.switch_weights[\"numerator_models\"] = numerator_models\n",
    "                self.switch_weights[\"denominator_models\"] = denominator_models\n",
    "                self.switch_weights[\"fitted\"] = True\n",
    "    \n",
    "            except KeyError as e:\n",
    "                raise ValueError(f\"Column not found in data for switch weights: {e}\")\n",
    "    \n",
    "        # 2. Censoring Weights (for both PP and ITT)\n",
    "        if self.censor_weights:\n",
    "            try:\n",
    "                num_features = [f.strip() for f in self.numerator_formula.split(\"+\")]\n",
    "                denom_features = [f.strip() for f in self.denominator_formula.split(\"+\")]\n",
    "                y_censor = 1 - self.data[self.censor_event].astype(int)\n",
    "    \n",
    "                if self.pool_models == \"numerator\":\n",
    "                    # Pooled numerator model\n",
    "                    X_num = sm.add_constant(self.data[num_features])\n",
    "                    numerator_model = sm.Logit(y_censor, X_num).fit(disp=0)\n",
    "                    p_num_all = numerator_model.predict(X_num)\n",
    "    \n",
    "                    # Denominator models by prev_treatment (period > 0)\n",
    "                    data_censor = self.data.dropna(subset=['prev_treatment'])\n",
    "                    y_censor_subset = 1 - data_censor[self.censor_event].astype(int)\n",
    "                    denominator_models = {}\n",
    "                    censor_weights = {}\n",
    "                    for prev_trt in [0, 1]:\n",
    "                        subset = data_censor[data_censor['prev_treatment'] == prev_trt]\n",
    "                        X_denom = sm.add_constant(subset[denom_features])\n",
    "                        denom_model = sm.Logit(y_censor_subset.loc[subset.index], X_denom).fit(disp=0)\n",
    "                        denominator_models[prev_trt] = denom_model\n",
    "                        p_denom = denom_model.predict(X_denom)\n",
    "                        p_num_subset = p_num_all.loc[subset.index]\n",
    "                        censor_weights[prev_trt] = p_num_subset / p_denom\n",
    "    \n",
    "                    self.censor_weights[\"Numerator Model\"] = numerator_model\n",
    "                    self.censor_weights[\"Denominator Models\"] = denominator_models\n",
    "    \n",
    "                elif self.pool_models == \"none\":\n",
    "                    # Both models stratified by prev_treatment (period > 0)\n",
    "                    data_censor = self.data.dropna(subset=['prev_treatment'])\n",
    "                    y_censor_subset = 1 - data_censor[self.censor_event].astype(int)\n",
    "                    numerator_models = {}\n",
    "                    denominator_models = {}\n",
    "                    censor_weights = {}\n",
    "                    for prev_trt in [0, 1]:\n",
    "                        subset = data_censor[data_censor['prev_treatment'] == prev_trt]\n",
    "                        y_current = y_censor_subset.loc[subset.index]\n",
    "                        X_num = sm.add_constant(subset[num_features])\n",
    "                        X_denom = sm.add_constant(subset[denom_features])\n",
    "    \n",
    "                        num_model = sm.Logit(y_current, X_num).fit(disp=0)\n",
    "                        denom_model = sm.Logit(y_current, X_denom).fit(disp=0)\n",
    "                        numerator_models[prev_trt] = num_model\n",
    "                        denominator_models[prev_trt] = denom_model\n",
    "    \n",
    "                        p_num = num_model.predict(X_num)\n",
    "                        p_denom = denom_model.predict(X_denom)\n",
    "                        censor_weights[prev_trt] = p_num / p_denom\n",
    "    \n",
    "                    self.censor_weights[\"Numerator Models\"] = numerator_models\n",
    "                    self.censor_weights[\"Denominator Models\"] = denominator_models\n",
    "    \n",
    "                # Assign censoring weights to data\n",
    "                self.data['censor_weight'] = 1.0  # Default for period = 0\n",
    "                for prev_trt in [0, 1]:\n",
    "                    mask = self.data['prev_treatment'] == prev_trt\n",
    "                    indices = data_censor[data_censor['prev_treatment'] == prev_trt].index\n",
    "                    self.data.loc[indices, 'censor_weight'] = censor_weights[prev_trt]\n",
    "    \n",
    "                self.censor_weights[\"Weight models fitted\"] = True\n",
    "    \n",
    "            except KeyError as e:\n",
    "                raise ValueError(f\"Column not found in data for censor weights: {e}\")\n",
    "\n",
    "    # Save models if path is provided\n",
    "    if save_path:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        if self.switch_weights.get(\"fitted\"):\n",
    "            for prev_trt in [0, 1]:\n",
    "                with open(os.path.join(save_path, f\"switch_num_model_prev_{prev_trt}.pkl\"), \"wb\") as f:\n",
    "                    pickle.dump(self.switch_weights[\"numerator_models\"][prev_trt], f)\n",
    "                with open(os.path.join(save_path, f\"switch_denom_model_prev_{prev_trt}.pkl\"), \"wb\") as f:\n",
    "                    pickle.dump(self.switch_weights[\"denominator_models\"][prev_trt], f)\n",
    "        if self.censor_weights and self.censor_weights[\"Weight models fitted\"]:\n",
    "            if self.pool_models == \"numerator\":\n",
    "                with open(os.path.join(save_path, \"censor_num_model.pkl\"), \"wb\") as f:\n",
    "                    pickle.dump(self.censor_weights[\"Numerator Model\"], f)\n",
    "                for prev_trt in [0, 1]:\n",
    "                    with open(os.path.join(save_path, f\"censor_denom_model_prev_{prev_trt}.pkl\"), \"wb\") as f:\n",
    "                        pickle.dump(self.censor_weights[\"Denominator Models\"][prev_trt], f)\n",
    "            elif self.pool_models == \"none\":\n",
    "                for prev_trt in [0, 1]:\n",
    "                    with open(os.path.join(save_path, f\"censor_num_model_prev_{prev_trt}.pkl\"), \"wb\") as f:\n",
    "                        pickle.dump(self.censor_weights[\"Numerator Models\"][prev_trt], f)\n",
    "                    with open(os.path.join(save_path, f\"censor_denom_model_prev_{prev_trt}.pkl\"), \"wb\") as f:\n",
    "                        pickle.dump(self.censor_weights[\"Denominator Models\"][prev_trt], f)\n",
    "\n",
    "    print(\"Weights calculated and models saved at:\", save_path)\n",
    "    return self\n",
    "    ###################################################\n",
    "    def set_censor_weight_model(self, censor_event, numerator, denominator, pool_models, model_fitter):\n",
    "        if censor_event not in self.data.columns:\n",
    "            raise ValueError(f\"Censor event column '{censor_event}' not found in data.\")\n",
    "\n",
    "        self.censor_event = censor_event\n",
    "        self.numerator_formula = numerator  # Use consistent attribute names\n",
    "        self.denominator_formula = denominator\n",
    "        self.pool_models = pool_models\n",
    "        self.model_fitter = model_fitter\n",
    "    \n",
    "        # Extract feature lists from formulas\n",
    "        num_features = [col.strip() for col in numerator.split(\"+\")]\n",
    "        denom_features = [col.strip() for col in denominator.split(\"+\")]\n",
    "        y = 1 - self.data[censor_event].astype(int)  # Probability of not being censored\n",
    "    \n",
    "        if pool_models == \"numerator\":\n",
    "            # Pooled numerator model on all data\n",
    "            X_num = sm.add_constant(self.data[num_features])\n",
    "            numerator_model = sm.Logit(y, X_num).fit(disp=0)\n",
    "    \n",
    "            # Separate denominator models for each prev_treatment (period > 0)\n",
    "            data_subset = self.data.dropna(subset=['prev_treatment'])  # Exclude period = 0\n",
    "            y_subset = 1 - data_subset[censor_event].astype(int)\n",
    "            denominator_models = {}\n",
    "            for prev_trt in [0, 1]:\n",
    "                subset = data_subset[data_subset['prev_treatment'] == prev_trt]\n",
    "                X_denom = sm.add_constant(subset[denom_features])\n",
    "                model = sm.Logit(y_subset.loc[subset.index], X_denom).fit(disp=0)\n",
    "                denominator_models[prev_trt] = model\n",
    "    \n",
    "            self.censor_weights = {\n",
    "                \"Numerator formula\": f\"1 - {censor_event} ~ {numerator}\",\n",
    "                \"Denominator formula\": f\"1 - {censor_event} ~ {denominator}\",\n",
    "                \"Model fitter type\": \"te_stats_glm_logit\",\n",
    "                \"Numerator Model\": numerator_model,\n",
    "                \"Denominator Models\": denominator_models\n",
    "            }\n",
    "    \n",
    "        elif pool_models == \"none\":\n",
    "            # Separate models for each prev_treatment (period > 0)\n",
    "            data_subset = self.data.dropna(subset=['prev_treatment'])  # Exclude period = 0\n",
    "            y_subset = 1 - data_subset[censor_event].astype(int)\n",
    "            numerator_models = {}\n",
    "            denominator_models = {}\n",
    "            for prev_trt in [0, 1]:\n",
    "                subset = data_subset[data_subset['prev_treatment'] == prev_trt]\n",
    "                y_current = y_subset.loc[subset.index]\n",
    "                # Numerator model\n",
    "                X_num = sm.add_constant(subset[num_features])\n",
    "                num_model = sm.Logit(y_current, X_num).fit(disp=0)\n",
    "                numerator_models[prev_trt] = num_model\n",
    "                # Denominator model\n",
    "                X_denom = sm.add_constant(subset[denom_features])\n",
    "                denom_model = sm.Logit(y_current, X_denom).fit(disp=0)\n",
    "                denominator_models[prev_trt] = denom_model\n",
    "    \n",
    "            self.censor_weights = {\n",
    "                \"Numerator formula\": f\"1 - {censor_event} ~ {numerator}\",\n",
    "                \"Denominator formula\": f\"1 - {censor_event} ~ {denominator}\",\n",
    "                \"Model fitter type\": \"te_stats_glm_logit\",\n",
    "                \"Numerator Models\": numerator_models,\n",
    "                \"Denominator Models\": denominator_models\n",
    "            }\n",
    "    \n",
    "        else:\n",
    "            raise ValueError(\"pool_models must be 'none' or 'numerator'.\")\n",
    "    \n",
    "        print(f\"Set censoring weight model:\\n{self.censor_weights}\")\n",
    "        return self\n",
    "###################################################\n",
    "    def show_weight_models(self):\n",
    "        \"\"\"Display summaries of fitted weight models.\"\"\"\n",
    "        if self.switch_weights.get(\"fitted\"):\n",
    "            print(\"Weight Models for Treatment Switching\")\n",
    "            print(\"-------------------------------------\")\n",
    "            for prev_trt in [0, 1]:\n",
    "                print(f\"\\nNumerator Model (prev_treatment = {prev_trt}):\")\n",
    "                print(self.switch_weights[\"numerator_models\"][prev_trt].summary())\n",
    "                print(f\"\\nDenominator Model (prev_treatment = {prev_trt}):\")\n",
    "                print(self.switch_weights[\"denominator_models\"][prev_trt].summary())\n",
    "    \n",
    "        if self.censor_weights and self.censor_weights.get(\"Weight models fitted\"):\n",
    "            print(\"\\nWeight Models for Informative Censoring\")\n",
    "            print(\"---------------------------------------\")\n",
    "            if self.pool_models == \"numerator\":\n",
    "                print(\"\\nPooled Numerator Model:\")\n",
    "                print(self.censor_weights[\"Numerator Model\"].summary())\n",
    "                for prev_trt in [0, 1]:\n",
    "                    print(f\"\\nDenominator Model (prev_treatment = {prev_trt}):\")\n",
    "                    print(self.censor_weights[\"Denominator Models\"][prev_trt].summary())\n",
    "            elif self.pool_models == \"none\":\n",
    "                for prev_trt in [0, 1]:\n",
    "                    print(f\"\\nNumerator Model (prev_treatment = {prev_trt}):\")\n",
    "                    print(self.censor_weights[\"Numerator Models\"][prev_trt].summary())\n",
    "                    print(f\"\\nDenominator Model (prev_treatment = {prev_trt}):\")\n",
    "                    print(self.censor_weights[\"Denominator Models\"][prev_trt].summary())\n",
    "###################################################\n",
    "    def apply_clustering(self, features, n_clusters=3):\n",
    "        \"\"\"Apply K-Means clustering to the dataset.\"\"\"\n",
    "        if not all(feature in self.data.columns for feature in features):\n",
    "            raise ValueError(\"Some clustering features are missing from the dataset.\")\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        self.data['cluster'] = kmeans.fit_predict(self.data[features])\n",
    "        print(\"Clustering applied successfully.\")\n",
    "###################################################\n",
    "    def apply_dichotomization(self, column, threshold=None):\n",
    "        \"\"\"Dichotomize a column based on a given threshold or median.\"\"\"\n",
    "        if column not in self.data.columns:\n",
    "            raise ValueError(f\"Column '{column}' not found in data.\")\n",
    "        \n",
    "        if threshold is None:\n",
    "            threshold = self.data[column].median()\n",
    "        binarizer = Binarizer(threshold=threshold)\n",
    "        self.data[column + \"_binary\"] = binarizer.fit_transform(self.data[[column]].values.reshape(-1, 1))\n",
    "        print(f\"Dichotomization applied to {column} with threshold {threshold}.\")\n",
    "###################################################\n",
    "    def __repr__(self):\n",
    "        \"\"\"Provide a string representation for debugging.\"\"\"\n",
    "        return (f\"TrialEmulation(id_col='{self.id_col}', period_col='{self.period_col}', \"\n",
    "                f\"treatment_col='{self.treatment_col}', outcome_col='{self.outcome_col}', \"\n",
    "                f\"eligible_col='{self.eligible_col}', data_shape={self.data.shape if self.data is not None else None})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "file_path = \"data/data_censored.csv\"\n",
    "data_censored = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Create directories for saving models\n",
    "trial_pp_dir = os.path.join(os.getcwd(), \"trial_pp\")\n",
    "trial_itt_dir = os.path.join(os.getcwd(), \"trial_itt\")\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Head:\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Head:\")\n",
    "print(data_censored.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "Dataset Head (5 rows):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  prev_treatment  \n",
      "0         0         1             NaN  \n",
      "1         0         0             1.0  \n",
      "2         0         0             1.0  \n",
      "3         0         0             1.0  \n",
      "4         0         0             1.0  \n"
     ]
    }
   ],
   "source": [
    "# Initialize and set data for per-protocol analysis\n",
    "trial_pp = TrialEmulation().set_data(\n",
    "    data_censored, \n",
    "    id_col=\"id\", \n",
    "    period_col=\"period\", \n",
    "    treatment_col=\"treatment\", \n",
    "    outcome_col=\"outcome\", \n",
    "    eligible_col=\"eligible\"\n",
    ")\n",
    "\n",
    "# Initialize and set data for ITT (Intention-To-Treat) without method chaining\n",
    "trial_itt = TrialEmulation()\n",
    "trial_itt.set_data(\n",
    "    data_censored, \n",
    "    id_col=\"id\", \n",
    "    period_col=\"period\", \n",
    "    treatment_col=\"treatment\", \n",
    "    outcome_col=\"outcome\", \n",
    "    eligible_col=\"eligible\"\n",
    ")\n",
    "\n",
    "print(\"---------------------------------------------------------------\")\n",
    "# Show the first few rows of trial_pp\n",
    "trial_pp.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Weight models and censoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Censoring due to treatment switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrialEmulation(id_col='id', period_col='period', treatment_col='treatment', outcome_col='outcome', eligible_col='eligible', data_shape=(725, 13))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set switch weight model\n",
    "trial_pp.set_switch_weight_model(\n",
    "    numerator=\"age\",\n",
    "    denominator=\"age + x1 + x3\",\n",
    "    model_fitter=stats_glm_logit\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Other informative censoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set censoring weight model:\n",
      "{'Numerator formula': '1 - censored ~ x2', 'Denominator formula': '1 - censored ~ x2 + x1', 'Model fitter type': 'te_stats_glm_logit', 'Numerator Models': {0: <statsmodels.discrete.discrete_model.BinaryResultsWrapper object at 0x0000024E062C9B50>, 1: <statsmodels.discrete.discrete_model.BinaryResultsWrapper object at 0x0000024E062CAB10>}, 'Denominator Models': {0: <statsmodels.discrete.discrete_model.BinaryResultsWrapper object at 0x0000024E062C8E90>, 1: <statsmodels.discrete.discrete_model.BinaryResultsWrapper object at 0x0000024E062CA3C0>}}\n",
      "Set censoring weight model:\n",
      "{'Numerator formula': '1 - censored ~ x2', 'Denominator formula': '1 - censored ~ x2 + x1', 'Model fitter type': 'te_stats_glm_logit', 'Numerator Model': <statsmodels.discrete.discrete_model.BinaryResultsWrapper object at 0x0000024E062C92B0>, 'Denominator Models': {0: <statsmodels.discrete.discrete_model.BinaryResultsWrapper object at 0x0000024E062CB7A0>, 1: <statsmodels.discrete.discrete_model.BinaryResultsWrapper object at 0x0000024E062CB770>}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrialEmulation(id_col='id', period_col='period', treatment_col='treatment', outcome_col='outcome', eligible_col='eligible', data_shape=(725, 13))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply censoring weight model to trial_pp\n",
    "trial_pp.set_censor_weight_model(\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    model_fitter=f\"{trial_pp_dir}/switch_models\"\n",
    ")\n",
    "\n",
    "# Apply censoring weight model to trial_itt\n",
    "trial_itt.set_censor_weight_model(\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"numerator\",\n",
    "    model_fitter=f\"{trial_itt_dir}/switch_models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calculate Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight models fitted and saved at: C:\\Users\\thris\\Documents\\Repo\\TTE_PY\\trial_pp\\switch_models\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Switch weight model has not been set.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m trial_pp\u001b[38;5;241m.\u001b[39mcalculate_weights(save_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(trial_pp_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswitch_models\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrial_itt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_itt_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mswitch_models\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m trial_pp\u001b[38;5;241m.\u001b[39mshow_weight_models()\n\u001b[0;32m      5\u001b[0m trial_itt\u001b[38;5;241m.\u001b[39mshow_weight_models()\n",
      "Cell \u001b[1;32mIn[10], line 61\u001b[0m, in \u001b[0;36mTrialEmulation.calculate_weights\u001b[1;34m(self, save_path)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data has been set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswitch_weights:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSwitch weight model has not been set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     num_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswitch_weights[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumerator\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m + \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Switch weight model has not been set."
     ]
    }
   ],
   "source": [
    "trial_pp.calculate_weights(save_path=os.path.join(trial_pp_dir, \"switch_models\"))\n",
    "trial_itt.calculate_weights(save_path=os.path.join(trial_itt_dir, \"switch_models\"))\n",
    "\n",
    "trial_pp.show_weight_models()\n",
    "trial_itt.show_weight_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
